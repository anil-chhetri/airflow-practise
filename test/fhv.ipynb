{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-20 06:29:38--  https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2019-02.parquet\n",
      "Resolving nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)... 52.217.170.121\n",
      "Connecting to nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)|52.217.170.121|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 15282636 (15M) [binary/octet-stream]\n",
      "Saving to: ‘fhv_tripdata_2019-02.parquet.1’\n",
      "\n",
      "fhv_tripdata_2019-0 100%[===================>]  14.57M  6.59MB/s    in 2.2s    \n",
      "\n",
      "2022-06-20 06:29:41 (6.59 MB/s) - ‘fhv_tripdata_2019-02.parquet.1’ saved [15282636/15282636]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2019-02.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fhv.ipynb  fhv_tripdata_2019-02.parquet  fhv_tripdata_2019-02.parquet.1\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow\n",
    "arrow_dataset = pyarrow.parquet.ParquetDataset('fhv_tripdata_2019-02.parquet')\n",
    "arrow_table = arrow_dataset.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2019-02-01 00:08:44</td>\n",
       "      <td>2019-02-01 00:23:35</td>\n",
       "      <td>264.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2019-02-01 00:27:51</td>\n",
       "      <td>2019-02-01 00:32:54</td>\n",
       "      <td>264.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2019-02-01 00:18:30</td>\n",
       "      <td>2019-02-01 00:25:45</td>\n",
       "      <td>264.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2019-02-01 00:43:15</td>\n",
       "      <td>2019-02-01 00:48:29</td>\n",
       "      <td>264.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2019-02-01 00:01:45</td>\n",
       "      <td>2019-02-01 00:09:13</td>\n",
       "      <td>264.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num     pickup_datetime    dropOff_datetime  PUlocationID  \\\n",
       "0               B00037 2019-02-01 00:08:44 2019-02-01 00:23:35         264.0   \n",
       "1               B00037 2019-02-01 00:27:51 2019-02-01 00:32:54         264.0   \n",
       "2               B00037 2019-02-01 00:18:30 2019-02-01 00:25:45         264.0   \n",
       "3               B00037 2019-02-01 00:43:15 2019-02-01 00:48:29         264.0   \n",
       "4               B00037 2019-02-01 00:01:45 2019-02-01 00:09:13         264.0   \n",
       "\n",
       "   DOlocationID  SR_Flag Affiliated_base_number  \n",
       "0         265.0      NaN                 B00037  \n",
       "1         265.0      NaN                 B00037  \n",
       "2         265.0      NaN                 B00037  \n",
       "3         265.0      NaN                 B00037  \n",
       "4         265.0      NaN                 B00037  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute '_ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/anilchhetri/dphi/airflow-practise/test/fhv.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bairflowdbt/home/anilchhetri/dphi/airflow-practise/test/fhv.ipynb#ch0000007vscode-remote?line=0'>1</a>\u001b[0m df\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mread_parquet(\u001b[39m\"\u001b[39;49m\u001b[39mfhv_tripdata_2019-02.parquet\u001b[39;49m\u001b[39m\"\u001b[39;49m, engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfastparquet\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bairflowdbt/home/anilchhetri/dphi/airflow-practise/test/fhv.ipynb#ch0000007vscode-remote?line=1'>2</a>\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parquet.py:493\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[39mLoad a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[39mDataFrame\u001b[39;00m\n\u001b[1;32m    490\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    491\u001b[0m impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[0;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    494\u001b[0m     path,\n\u001b[1;32m    495\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m    496\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    497\u001b[0m     use_nullable_dtypes\u001b[39m=\u001b[39;49muse_nullable_dtypes,\n\u001b[1;32m    498\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    499\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parquet.py:347\u001b[0m, in \u001b[0;36mFastParquetImpl.read\u001b[0;34m(self, path, columns, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m     path \u001b[39m=\u001b[39m handles\u001b[39m.\u001b[39mhandle\n\u001b[1;32m    345\u001b[0m parquet_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39mParquetFile(path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparquet_kwargs)\n\u001b[0;32m--> 347\u001b[0m result \u001b[39m=\u001b[39m parquet_file\u001b[39m.\u001b[39;49mto_pandas(columns\u001b[39m=\u001b[39;49mcolumns, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    349\u001b[0m \u001b[39mif\u001b[39;00m handles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     handles\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fastparquet/api.py:751\u001b[0m, in \u001b[0;36mParquetFile.to_pandas\u001b[0;34m(self, columns, categories, filters, index, row_filter)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    748\u001b[0m     parts \u001b[39m=\u001b[39m {name: (v \u001b[39mif\u001b[39;00m name\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m-catdef\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    749\u001b[0m                     \u001b[39melse\u001b[39;00m v[start:start \u001b[39m+\u001b[39m thislen])\n\u001b[1;32m    750\u001b[0m              \u001b[39mfor\u001b[39;00m (name, v) \u001b[39min\u001b[39;00m views\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m--> 751\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_row_group_file(rg, columns, categories, index,\n\u001b[1;32m    752\u001b[0m                              assign\u001b[39m=\u001b[39;49mparts, partition_meta\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartition_meta,\n\u001b[1;32m    753\u001b[0m                              row_filter\u001b[39m=\u001b[39;49msel, infile\u001b[39m=\u001b[39;49minfile)\n\u001b[1;32m    754\u001b[0m     start \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m thislen\n\u001b[1;32m    755\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fastparquet/api.py:361\u001b[0m, in \u001b[0;36mParquetFile.read_row_group_file\u001b[0;34m(self, rg, columns, categories, index, assign, partition_meta, row_filter, infile)\u001b[0m\n\u001b[1;32m    358\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    359\u001b[0m f \u001b[39m=\u001b[39m infile \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopen(fn, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 361\u001b[0m core\u001b[39m.\u001b[39;49mread_row_group(\n\u001b[1;32m    362\u001b[0m     f, rg, columns, categories, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mschema, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcats,\n\u001b[1;32m    363\u001b[0m     selfmade\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mselfmade, index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    364\u001b[0m     assign\u001b[39m=\u001b[39;49massign, scheme\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfile_scheme, partition_meta\u001b[39m=\u001b[39;49mpartition_meta,\n\u001b[1;32m    365\u001b[0m     row_filter\u001b[39m=\u001b[39;49mrow_filter\n\u001b[1;32m    366\u001b[0m )\n\u001b[1;32m    367\u001b[0m \u001b[39mif\u001b[39;00m ret:\n\u001b[1;32m    368\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fastparquet/core.py:608\u001b[0m, in \u001b[0;36mread_row_group\u001b[0;34m(file, rg, columns, categories, schema_helper, cats, selfmade, index, assign, scheme, partition_meta, row_filter)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[39mif\u001b[39;00m assign \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    607\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mGoing with pre-allocation!\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 608\u001b[0m read_row_group_arrays(file, rg, columns, categories, schema_helper,\n\u001b[1;32m    609\u001b[0m                       cats, selfmade, assign\u001b[39m=\u001b[39;49massign, row_filter\u001b[39m=\u001b[39;49mrow_filter)\n\u001b[1;32m    611\u001b[0m \u001b[39mfor\u001b[39;00m cat \u001b[39min\u001b[39;00m cats:\n\u001b[1;32m    612\u001b[0m     \u001b[39mif\u001b[39;00m cat \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m assign:\n\u001b[1;32m    613\u001b[0m         \u001b[39m# do no need to have partition columns in output\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fastparquet/core.py:580\u001b[0m, in \u001b[0;36mread_row_group_arrays\u001b[0;34m(file, rg, columns, categories, schema_helper, cats, selfmade, assign, row_filter)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m columns:\n\u001b[1;32m    578\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m read_col(column, schema_helper, file, use_cat\u001b[39m=\u001b[39;49mname\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m-catdef\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39min\u001b[39;49;00m out,\n\u001b[1;32m    581\u001b[0m          selfmade\u001b[39m=\u001b[39;49mselfmade, assign\u001b[39m=\u001b[39;49mout[name],\n\u001b[1;32m    582\u001b[0m          catdef\u001b[39m=\u001b[39;49mout\u001b[39m.\u001b[39;49mget(name\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m-catdef\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    583\u001b[0m          row_filter\u001b[39m=\u001b[39;49mrow_filter)\n\u001b[1;32m    585\u001b[0m \u001b[39mif\u001b[39;00m _is_map_like(schema_helper, column):\n\u001b[1;32m    586\u001b[0m     \u001b[39m# TODO: could be done in fast loop in _assemble_objects?\u001b[39;00m\n\u001b[1;32m    587\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m maps:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fastparquet/core.py:549\u001b[0m, in \u001b[0;36mread_col\u001b[0;34m(column, schema_helper, infile, use_cat, selfmade, assign, catdef, row_filter)\u001b[0m\n\u001b[1;32m    547\u001b[0m     piece[:] \u001b[39m=\u001b[39m i\u001b[39m.\u001b[39mcodes\n\u001b[1;32m    548\u001b[0m \u001b[39melif\u001b[39;00m d \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m use_cat:\n\u001b[0;32m--> 549\u001b[0m     piece[:] \u001b[39m=\u001b[39m dic[val]\n\u001b[1;32m    550\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m use_cat:\n\u001b[1;32m    551\u001b[0m     piece[:] \u001b[39m=\u001b[39m convert(val, se)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/arrays/datetimelike.py:395\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mif\u001b[39;00m no_op:\n\u001b[1;32m    393\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 395\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__setitem__\u001b[39;49m(key, value)\n\u001b[1;32m    396\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_clear_freq()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/arrays/_mixins.py:249\u001b[0m, in \u001b[0;36mNDArrayBackedExtensionArray.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__setitem__\u001b[39m(\u001b[39mself\u001b[39m, key, value):\n\u001b[1;32m    248\u001b[0m     key \u001b[39m=\u001b[39m check_array_indexer(\u001b[39mself\u001b[39m, key)\n\u001b[0;32m--> 249\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_setitem_value(value)\n\u001b[1;32m    250\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ndarray[key] \u001b[39m=\u001b[39m value\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/arrays/datetimelike.py:745\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._validate_setitem_value\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    743\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_scalar(value, allow_listlike\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 745\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_unbox(value, setitem\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/arrays/datetimelike.py:758\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._unbox\u001b[0;34m(self, other, setitem)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    756\u001b[0m     \u001b[39m# same type as self\u001b[39;00m\n\u001b[1;32m    757\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_compatible_with(other, setitem\u001b[39m=\u001b[39msetitem)\n\u001b[0;32m--> 758\u001b[0m     other \u001b[39m=\u001b[39m other\u001b[39m.\u001b[39;49m_ndarray\n\u001b[1;32m    759\u001b[0m \u001b[39mreturn\u001b[39;00m other\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute '_ndarray'"
     ]
    }
   ],
   "source": [
    "df=pd.read_parquet(\"fhv_tripdata_2019-02.parquet\", engine=\"fastparquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x7fe341ed1790>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_string = \"postgresql+psycopg2://postgres:postgres@localhost/dphi\"\n",
    "conn = create_engine(conn_string)\n",
    "conn.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00001</td>\n",
       "      <td>2019-01-01 00:30:00</td>\n",
       "      <td>2019-01-01 02:51:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00001</td>\n",
       "      <td>2019-01-01 00:45:00</td>\n",
       "      <td>2019-01-01 00:54:49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00001</td>\n",
       "      <td>2019-01-01 00:15:00</td>\n",
       "      <td>2019-01-01 00:54:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00008</td>\n",
       "      <td>2019-01-01 00:19:00</td>\n",
       "      <td>2019-01-01 00:39:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00008</td>\n",
       "      <td>2019-01-01 00:27:00</td>\n",
       "      <td>2019-01-01 00:37:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num      pickup_datetime     dropOff_datetime  \\\n",
       "0               B00001  2019-01-01 00:30:00  2019-01-01 02:51:55   \n",
       "1               B00001  2019-01-01 00:45:00  2019-01-01 00:54:49   \n",
       "2               B00001  2019-01-01 00:15:00  2019-01-01 00:54:52   \n",
       "3               B00008  2019-01-01 00:19:00  2019-01-01 00:39:00   \n",
       "4               B00008  2019-01-01 00:27:00  2019-01-01 00:37:00   \n",
       "\n",
       "   PUlocationID  DOlocationID  SR_Flag Affiliated_base_number  \n",
       "0           NaN           NaN      NaN                 B00001  \n",
       "1           NaN           NaN      NaN                 B00001  \n",
       "2           NaN           NaN      NaN                 B00001  \n",
       "3           NaN           NaN      NaN                 B00008  \n",
       "4           NaN           NaN      NaN                 B00008  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/fhv_tripdata_2019-01.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num       object\n",
       "pickup_datetime            object\n",
       "dropOff_datetime           object\n",
       "PUlocationID              float64\n",
       "DOlocationID              float64\n",
       "SR_Flag                   float64\n",
       "Affiliated_base_number     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of          dispatching_base_num      pickup_datetime     dropOff_datetime  \\\n",
       "0                      B00001  2019-01-01 00:30:00  2019-01-01 02:51:55   \n",
       "1                      B00001  2019-01-01 00:45:00  2019-01-01 00:54:49   \n",
       "2                      B00001  2019-01-01 00:15:00  2019-01-01 00:54:52   \n",
       "3                      B00008  2019-01-01 00:19:00  2019-01-01 00:39:00   \n",
       "4                      B00008  2019-01-01 00:27:00  2019-01-01 00:37:00   \n",
       "...                       ...                  ...                  ...   \n",
       "23159059               B03157  2019-01-31 23:21:00  2019-01-31 23:28:52   \n",
       "23159060               B03157  2019-01-31 23:38:04  2019-01-31 23:45:43   \n",
       "23159061               B03157  2019-01-31 23:53:58  2019-02-01 00:25:04   \n",
       "23159062               B03157  2019-01-31 23:54:53  2019-02-01 00:00:14   \n",
       "23159063               B03164  2019-01-31 23:55:47  2019-02-01 00:24:29   \n",
       "\n",
       "          PUlocationID  DOlocationID  SR_Flag Affiliated_base_number  \n",
       "0                  NaN           NaN      NaN                 B00001  \n",
       "1                  NaN           NaN      NaN                 B00001  \n",
       "2                  NaN           NaN      NaN                 B00001  \n",
       "3                  NaN           NaN      NaN                 B00008  \n",
       "4                  NaN           NaN      NaN                 B00008  \n",
       "...                ...           ...      ...                    ...  \n",
       "23159059           NaN         265.0      NaN                 B03157  \n",
       "23159060           NaN         265.0      NaN                 B03157  \n",
       "23159061           NaN         265.0      NaN                 B03157  \n",
       "23159062           NaN         265.0      NaN                 B03157  \n",
       "23159063           NaN         265.0      NaN                 B03164  \n",
       "\n",
       "[23159064 rows x 7 columns]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
